{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from os import listdir\n",
      "from multiprocessing import Pool, cpu_count\n",
      "from pylab import imread\n",
      "from time import time\n",
      "\n",
      "# For image manipulation\n",
      "import numpy as np\n",
      "from skimage import color\n",
      "from skimage import data\n",
      "from skimage import feature\n",
      "from skimage import filter\n",
      "from skimage.filter import rank\n",
      "from skimage import morphology\n",
      "from skimage import measure\n",
      "from skimage import segmentation\n",
      "from skimage import util\n",
      "from sklearn import decomposition\n",
      "\n",
      "MYDIRECTORY = os.path.join('.', '50_categories')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2) **Compute features for one of the images**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Take in one image only, and extract features from that image\n",
      "def extractFeaturesFromOneImage(imagePath):\n",
      "    features = []\n",
      "    imageArray = imread(imagePath)\n",
      "    greyImage = color.rgb2grey(imageArray)\n",
      "    \n",
      "    # Image array size\n",
      "    features.append(imageArray.size)\n",
      "    \n",
      "    # Average of each RGB channel\n",
      "    RGBavg = np.average(np.mean(imageArray, axis=0), axis=0)\n",
      "    for part in RGBavg:                        \n",
      "        features.append(part)\n",
      "        \n",
      "    # Cross correlation between the RGB channels\n",
      "    RGBsum = np.sum(imageArray, axis=0)\n",
      "    red = RGBsum[:, 0]\n",
      "    green = RGBsum[:, 1]\n",
      "    blue = RGBsum[:, 2]\n",
      "    features.append(np.mean(np.correlate(red, green)))\n",
      "    features.append(np.mean(np.correlate(blue, red)))\n",
      "    features.append(np.mean(np.correlate(green, blue)))\n",
      "    \n",
      "    # Corner detection with features\n",
      "    features.append(np.mean(feature.corner_harris(imageArray)))\n",
      "    features.append(np.mean(feature.peak_local_max(imageArray)))\n",
      "    \n",
      "    # PCA\n",
      "    pca = decomposition.PCA(n_components=5)\n",
      "    PCARedFeatures = pca.fit_transform(imageArray[:, :, 0])\n",
      "    PCAGreenFeatures = pca.fit_transform(imageArray[:, :, 1])\n",
      "    PCABlueFeatures = pca.fit_transform(imageArray[:, :, 2])\n",
      "    features.append(np.mean(PCARedFeatures))\n",
      "    features.append(np.mean(PCAGreenFeatures))\n",
      "    features.append(np.mean(PCABlueFeatures))\n",
      "    \n",
      "    for ratio in pca.explained_variance_ratio_:\n",
      "        features.append(ratio)\n",
      "        \n",
      "    # Proportion of pixels that are part of edges\n",
      "    hEdges = np.mean(filter.hsobel(greyImage))\n",
      "    features.append(hEdges)\n",
      "    vEdges = np.mean(filter.vsobel(greyImage))\n",
      "    features.append(vEdges)\n",
      "    \n",
      "    # Segmentation\n",
      "    felzenszwalbSeg = np.mean(segmentation.felzenszwalb(imageArray))\n",
      "    features.append(felzenszwalbSeg)\n",
      "    \n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Parallelizing code adapted from Josh and Adam's version to extract features for all images**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "#print iris['data']\n",
      "#print iris['target']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# FUNCTION DEFINITIONS\n",
      "# Quick function to divide up a large list into multiple small lists, \n",
      "# attempting to keep them all the same size. \n",
      "def split_seq(seq, size):\n",
      "  newseq = []\n",
      "  splitsize = 1.0/size*len(seq)\n",
      "  for i in range(size):\n",
      "    newseq.append(seq[int(round(i*splitsize)):\n",
      "      int(round((i+1)*splitsize))])\n",
      "  return newseq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractCategory(imagePath):\n",
      "  return imagePath[imagePath.find('/', 2)+1:imagePath.rfind('/')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Our simple feature extraction function. It takes in a list of image paths, \n",
      "# does some measurement on each image, then returns a list of the image paths\n",
      "# paired with the results of the feature measurement.\n",
      "def extract_features(image_path_list):\n",
      "  feature_list = []\n",
      "  for image_path in image_path_list:\n",
      "    # This feature is simple. You can modify this\n",
      "    # code to produce more complicated features and to produce multiple\n",
      "    # features in one function call.\n",
      "    try:\n",
      "      features = extractFeaturesFromOneImage(image_path)\n",
      "      features.append(image_path)\n",
      "      features.append(extractCategory(image_path))\n",
      "      feature_list.append(features)\n",
      "    except:\n",
      "      pass\n",
      "  return feature_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We first collect all the local paths to all the images in one list\n",
      "image_paths = []\n",
      "categories = listdir(MYDIRECTORY)\n",
      "for category in categories:\n",
      "  image_names = listdir(MYDIRECTORY  + \"/\" + category) \n",
      "  for name in image_names:\n",
      "    image_paths.append(MYDIRECTORY + \"/\" + category + \"/\" + name)\n",
      "\n",
      "print (\"There should be 4244 images, actual number is \" + \n",
      "  str(len(image_paths)) + \".\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There should be 4244 images, actual number is 4244.\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Then, we run the feature extraction function using multiprocessing.Pool so \n",
      "# so that we can parallelize the process and run it much faster.\n",
      "numprocessors = cpu_count() # To see results of parallelizing, set numprocessors\n",
      "                            # to less than cpu_count().\n",
      "print \"Number of processors:\", numprocessors\n",
      "# numprocessors = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of processors: 4\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We have to cut up the image_paths list into the number of processes we want to run. \n",
      "split_image_paths = split_seq(image_paths, numprocessors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ok, this block is where the parallel code runs. \n",
      "# We time it so we can get a feel for the speed up.\n",
      "start_time = time()\n",
      "p = Pool(numprocessors)\n",
      "result = p.map_async(extract_features, split_image_paths)\n",
      "poolresult = result.get()\n",
      "end_time = time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# All done, print timing results.\n",
      "print (\"Finished extracting features. Total time: \" + \n",
      "  str(round(end_time-start_time, 3)) + \" s, or \" + \n",
      "  str( round( (end_time-start_time)/len(image_paths), 5 ) ) + \" s/image.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished extracting features. Total time: 6609.305 s, or 1.55733 s/image.\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To tidy-up a bit, we loop through the poolresult to create a final list of\n",
      "# the feature extraction results for all images.\n",
      "combined_result = []\n",
      "for single_proc_result in poolresult:\n",
      "  for single_image_result in single_proc_result:\n",
      "    combined_result.append(single_image_result)\n",
      "print len(combined_result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4210\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "#pickle.dump(combined_result, open('combined_result.p', 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3) **Build a random forest classifier for the training set**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_result = pickle.load(open('combined_result.p', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = np.asarray([c[-1] for c in combined_result])\n",
      "data = np.asarray([c[:-2] for c in combined_result])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier(n_estimators=100, n_jobs=4, compute_importances=True)\n",
      "clf.fit(data, target)\n",
      "pickle.dump(clf, open('trained_classifier.p','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/khoatran/software/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.py:783: DeprecationWarning: Setting compute_importances is no longer required as version 0.14. Variable importances are now computed on the fly when accessing the feature_importances_ attribute. This parameter will be removed in 0.16.\n",
        "  DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = pickle.load(open('trained_classifier.p', 'r'))\n",
      "print clf.feature_importances_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.09780404  0.05818933  0.06087046  0.06094865  0.04860952  0.04912002\n",
        "  0.04883157  0.07130041  0.06099553  0.          0.          0.\n",
        "  0.05604896  0.05280551  0.05161038  0.0510989   0.0529821   0.06382474\n",
        "  0.07692366  0.03803621]\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold\n",
      "scores = cross_val_score(clf, data, target, cv=10, n_jobs=1)\n",
      "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.28 (+/- 0.05)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "4) **A function that can take it a path and a pickled forest**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_final_classifier(path, forest=os.path.join('.', 'trained_classifier.p')):\n",
      "    clf = pickle.load(open('trained_classifier.p', 'r'))\n",
      "    images = listdir(path)\n",
      "    print \"%-40s\" % \"filename\", \"%-40s\" % \"predicted_class\"\n",
      "    print \"\".join([\"-\" for i in range(60)])\n",
      "    for image in images:\n",
      "        predict = clf.predict(extractFeaturesFromOneImage(path + '/' + image))\n",
      "        print \"%-40s\" % image, \"%-40s\" % predict\n",
      "        \n",
      "run_final_classifier(\"testing\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "filename                       predicted_class               \n",
        "------------------------------------------------------------\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "453761main_ng_select_atw_final_1600x1200_full.jpg ['swan']                      \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "airplane.jpg                   ['speed-boat']                \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dolphin-kristian-sekulic-isp.jpg ['killer-whale']              \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dolphin-face-1.jpg             ['cormorant']                 \n"
       ]
      }
     ],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}